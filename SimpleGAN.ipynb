{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>An Introduction to</center>\n",
    "# <center>Generative Adversarial Networks</center>\n",
    "# <center>with PyTorch</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### David Mertz\n",
    "\n",
    "  * Data Scientist\n",
    "  * Chief Technology Officer, Bold Metrics Inc.\n",
    "  * Trainer\n",
    "  * Pythonista\n",
    "  \n",
    "### mertz@kdm.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative Adversarial Networks (GANs)\n",
    "\n",
    "### GANs  have been used most widely in image generation contexts\n",
    "### Can be applied equally to other domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### When applied to images, GAN's often produce \"surreal\" and sometimes disturbing resemblances to real images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "### While a GAN is *technically* a kind of unsupervised learning, it cleverly captures much of the power of supervised learning models. \n",
    "\n",
    "(... what's the difference?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Supervised learning\n",
    "\n",
    "* Start out with **tagged training data**\n",
    "  * Classifiers predict target in several classes\n",
    "  * Regressors predict target in continuous numeric range\n",
    "* Require initial mechanism to identify canonical answers (e.g. human judgement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Unsupervised learning\n",
    "\n",
    "* Data features, but no target per se\n",
    "* No *a priori* to compare to prediction\n",
    "* E.g. **clustering**, **decomposition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Generative Adversarial Network\n",
    "\n",
    "* Only examples of the positive class\n",
    "* Implicit negative class of \"anything else\"\n",
    "* The \"adversaries\" are supervised models\n",
    "* The adversaries provide each other's targets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Artist and AI enthusiast Robbie Barrat made these [images derived from painted nudes](https://twitter.com/DrBeef_/status/978732422085988352/photo/1?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E978732422085988352&ref_url=https%3A%2F%2Fwww.zmescience.com%2Fscience%2Fai-nudes-surreal-185131341%2F):\n",
    "\n",
    "![GAN Nudes](img/GAN-nudes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Martin Giles in [MIT Technology Review](https://www.technologyreview.com/s/610253/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/) shows authentic seeming generated images of \"fake celebrities:\"\n",
    "\n",
    "![GAN celebs](img/GAN-celebs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One neural network in a GAN is a \"generator\"\n",
    "\n",
    "* Generate new data that cannot be distinguished from genuine samples\n",
    "* We start with training datasets, but do not know what identifies correctness.  \n",
    "* Correctness is defined by \"belonging to the training set\" \n",
    "* ...as opposed to being any other (distribution of) possible values for the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The second neural network is a \"discriminator.\" \n",
    "* Distinguish synthetic samples from genuine ones\n",
    "* The discriminator uses supervised learning, since **we** know which images are fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Real world versus GANs:\n",
    "\n",
    "* Real world data is rarely activately tryin to fool a network\n",
    "* GAN: generator is specifically trying to outwit the discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However...  \n",
    "\n",
    "* In forgery or fraud, a malicious actor is trying to create currency, or artwork, or some other item that can pass inspection by (human or machine) discriminators\n",
    "* In evolution, some organisms use camouflage to appear as something else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This O'Reilly Press illustration is a good overview of the structure of a GAN:\n",
    "\n",
    "![GAN schema](img/gan_schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Super-Resolution\n",
    "\n",
    "A fascinating application of GANs is [super-resolution](https://arxiv.org/abs/1609.04802).\n",
    "\n",
    "Essentially, we train the discriminator to recognize \"high-resolution\" and provide the generator with low-resolution, but real, images as its input vector.\n",
    "\n",
    "![Super-resolution](img/super-resolution.png)\n",
    "\n",
    "Image credit: [Christopher Thomas](https://towardsdatascience.com/deep-learning-based-super-resolution-without-using-a-gan-11c9bb5b6cd5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A toy example\n",
    "\n",
    "The code shown is adapted from a GAN written by Dev Nag in his blog post [Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch)](https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f).  \n",
    "\n",
    "For simplicity of presentation, all this GAN is trying to learn is a Gaussian random distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b6b0e7f7106f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkurtosis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import sigmoid, tanh, relu\n",
    "\n",
    "# For demonstration, we can use CPU target if CUDA not available\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Check the status of the GPU (if present)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.memory_allocated()\n",
    "    # *MUCH* faster to run on GPU\n",
    "    device = torch.device('cuda') \n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create the dataset\n",
    "\n",
    "We can easily create samples from a Gaussian distribution.  The **features** we will us to characterize a sample are the first four moments of the sample; we could easily use the raw points, or other abstractions of the \"shape\" of the data, as we wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```python\n",
    "def decorate_with_diffs(data, exponent, remove_raw_data=False):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - mean_broadcast, exponent)\n",
    "    if remove_raw_data:\n",
    "        return torch.cat([diffs], 1)\n",
    "    else:\n",
    "        return torch.cat([data, diffs], 1)\n",
    "    \n",
    "# Unused data features (experiment with these on your own).\n",
    "# Raw data\n",
    "preprocess, get_num_features = lambda data: data, lambda x: x\n",
    "# Data and variances\n",
    "preprocess, get_num_features = lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2\n",
    "# Data and diffs\n",
    "preprocess, get_num_features = lambda data: decorate_with_diffs(data, 1.0), lambda x: x * 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_moments(d):\n",
    "    # Return the first 4 moments of the data provided\n",
    "    mean = torch.mean(d)\n",
    "    diffs = d - mean\n",
    "    var = torch.mean(torch.pow(diffs, 2.0))\n",
    "    std = torch.pow(var, 0.5)\n",
    "    zscores = diffs / std\n",
    "    skews = torch.mean(torch.pow(zscores, 3.0))\n",
    "    # excess kurtosis, should be 0 for Gaussian\n",
    "    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  \n",
    "    final = torch.cat((mean.reshape(1,), std.reshape(1,), \n",
    "                       skews.reshape(1,), kurtoses.reshape(1,)))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Data points\n",
    "def d_sampler(n=500, mu=4, sigma=1.25):\n",
    "    \"Provide `n` random Gaussian distributed points with mean `mu` and std `sigma`\"\n",
    "    return torch.Tensor(np.random.normal(mu, sigma, n)).to(device)\n",
    "\n",
    "def gi_sampler(m=500, n=1):\n",
    "    \"Uniform-dist data into generator, NOT Gaussian\"\n",
    "    return torch.rand(m, n).to(device)\n",
    "\n",
    "preprocess = get_moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist() \n",
    "\n",
    "def stats(v):\n",
    "    d = extract(v)\n",
    "    return (np.mean(d), np.std(d), skew(d), kurtosis(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualize a sample from the target distribution\n",
    "\n",
    "Reminder of what we are trying to imitate with the GAN.  \n",
    "\n",
    "* Since these are samples, somewhat different each time we pull from distribution\n",
    "* For a large sample (5000 here) the \"shape\" is obvious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "v = d_sampler(5000)\n",
    "print(\"Mean: %.2f | Std: %.2f | Skew: %.2f | Kurt: %2f\" % stats(v))\n",
    "plt.hist(v.cpu(), bins=100)\n",
    "plt.title(\"A sample from the target distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Visualize a sample from the target distribution (continued)\n",
    "\n",
    "* In GAN presented here, samples are 500 points from the same distribution\n",
    "* Looks much more \"stochastic\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "v = d_sampler()\n",
    "print(\"Mean: %.2f | Std: %.2f | Skew: %.2f | Kurt: %2f\" % stats(v))\n",
    "plt.hist(v.cpu(), bins=100)\n",
    "plt.title(\"A small sample from the target distribution\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v = gi_sampler(5000).flatten()\n",
    "print(\"Mean: %.2f | Std: %.2f | Skew: %.2f | Kurt: %2f\" % stats(v))\n",
    "plt.hist(v.cpu(), bins=100)\n",
    "plt.title(\"A sample from the noise distribution\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v = gi_sampler().flatten()\n",
    "print(\"Mean: %.2f | Std: %.2f | Skew: %.2f | Kurt: %2f\" % stats(v))\n",
    "plt.hist(v.cpu(), bins=100)\n",
    "plt.title(\"A small sample from the noise distribution\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the Models\n",
    "\n",
    "Define a generator and a discriminator in a standard fashion for PyTorch models.  Both have 3 linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = self.dropout(x)  # Can we avoid a local trap?\n",
    "        x = self.f(x)\n",
    "        x = self.map2(x)\n",
    "        x = self.dropout(x)  # Can we avoid a local trap?\n",
    "        x = self.f(x)\n",
    "        x = self.map3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map2(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map3(x)\n",
    "        x = self.f(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Instantiate models, loss, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "minibatch_size = 4\n",
    "num_epochs = 5000\n",
    "print_interval = 500\n",
    "d_steps = 20\n",
    "g_steps = 20\n",
    "\n",
    "G = Generator(input_size=1,   # Random noise dimension, per output vector\n",
    "              hidden_size=10, # Generator complexity\n",
    "              output_size=1,  # Single output for successful forgery or not\n",
    "              f=relu          # Activation function\n",
    "             ).to(device)\n",
    "\n",
    "# Use input_size = get_num_features(...) if you try other examples\n",
    "D = Discriminator(input_size=4,   # 4 moments/features\n",
    "                  hidden_size=10, # Discriminator complexity\n",
    "                  output_size=1,  # Single output for 'real' vs. 'fake' classification\n",
    "                  f=sigmoid       # Activation function\n",
    "                 ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "criterion = nn.BCELoss()  \n",
    "\n",
    "# Stochastic Gradient Descent optimizers\n",
    "d_learning_rate = 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "sgd_momentum = 0.9\n",
    "d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
    "g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train the model\n",
    "\n",
    "During training we will show some information and visualization of the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def train(minibatch_size=500, g_input_size=1, d_input_size=500):\n",
    "    for epoch in range(num_epochs):\n",
    "        for d_index in range(d_steps):\n",
    "            # 1. Train D on real+fake\n",
    "            D.zero_grad()\n",
    "\n",
    "            #  1A: Train D on real\n",
    "            d_real_data = d_sampler(d_input_size)\n",
    "            d_real_decision = D(preprocess(d_real_data))\n",
    "            d_real_error = criterion(d_real_decision, torch.ones([1]).to(device))  # ones = true\n",
    "            d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "            #  1B: Train D on fake\n",
    "            d_gen_input = gi_sampler(minibatch_size, g_input_size)\n",
    "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "            d_fake_error = criterion(d_fake_decision, torch.zeros([1]).to(device))  # zeros = fake\n",
    "            d_fake_error.backward()\n",
    "            d_optimizer.step()     # Only optimizes D's parameters; \n",
    "                                   # changes based on stored gradients from backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "        for g_index in range(g_steps):\n",
    "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "            G.zero_grad()\n",
    "\n",
    "            gen_input = gi_sampler(minibatch_size, g_input_size)\n",
    "            g_fake_data = G(gen_input)\n",
    "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "            # Train G to pretend it's genuine\n",
    "            g_error = criterion(dg_fake_decision, torch.ones([1]).to(device))\n",
    "\n",
    "            g_error.backward()\n",
    "            g_optimizer.step()  # Only optimizes G's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "        if epoch % print_interval == 0:\n",
    "            rstats, fstats = stats(d_real_data), stats(d_fake_data)\n",
    "            print(\"Epoch\", epoch, \"\\n\",\n",
    "                  \"Real Dist: Mean: %.2f, Std: %.2f, Skew: %.2f, Kurt: %2f\\n\" % tuple(rstats),\n",
    "                  \"Fake Dist: Mean: %.2f, Std: %.2f, Skew: %.2f, Kurt: %2f\" % tuple(fstats))\n",
    "\n",
    "            values = extract(g_fake_data)\n",
    "            plt.hist(values, bins=100)\n",
    "            plt.xlabel('Value')\n",
    "            plt.ylabel('Count')\n",
    "            plt.title('Histogram of Generated Distribution (epoch %d)' % epoch)\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pitfalls and guidelines\n",
    "\n",
    "When you train the discriminator, the generator will remain contant, and vice versa.  This gives each model a static adversary. If you have a roughly known domain, you might wish to pretrain the discriminator on similar data before starting your training of the generator.  This gives the generator a more difficult adversary to work against.\n",
    "\n",
    "Depending on the details of the network you configue, as well as other options in their training regimes, learning rates, optimizers, loss functions, and so on, one side of the GAN can overpower the other. If the discriminator is too good, it will return values  close to 0 or 1, and that the generator will be unable to find a meaningful gradient. If the generator is too good, it will exploit weaknesses in the discriminator that lead to false negatives. \n",
    "\n",
    "---\n",
    "\n",
    "Dev Nag, in his blog post that I base this lesson on, present results from multiple runs of and identical GAN, mostly the same at the one in this notebook.  At times it does quite well, but at other times—just depending on randomized initial conditions—it does extremely poorly.  Sometimes additional training rounds may force them out of a poor local maximum, but often an unbalance is reached where progress is not possible.  I am *curious*, and explore it passingly above, whether addition of dropout layers or other layer engineering might mitigate this danger.\n",
    "\n",
    "![GAN generated distributions](img/GAN-generated-distributions.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
